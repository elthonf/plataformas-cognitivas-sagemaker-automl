{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumo simples, carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"blazingtext-2020-04-13-17-24-41-436\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"awesome\", \"awweeesome\"]\n",
    "payload = {\"instances\" : words}\n",
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  Body=json.dumps(payload))\n",
    "response_body = response['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_str = response_body.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_str.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos avaliar a qualidade dessa representação vetorial na tarefa de similaridade / relação de palavras. Fazemos isso calculando o coeficiente de correlação de Spearman (Spearman, 1904) entre o julgamento humano e a semelhança de cosseno entre as representações vetoriais. Como está em inglês, usamos o [rare word dataset (RW)](https://nlp.stanford.edu/~lmthang/morphoNLM/), apresentado por Luong et al. (2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_words = []\n",
    "with open(\"datasets/textmining/rare_words.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        query_words.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_words = list(set(query_words)) #Ordena e deixa em lista\n",
    "total_words = len(query_words)\n",
    "vectors = {}\n",
    "print(\"Total words: {0}\".format(total_words ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "batch_size = 500\n",
    "batch_start = 0\n",
    "batch_end = batch_start + batch_size\n",
    "while len(vectors) != total_words:\n",
    "    batch_end = min(batch_end, total_words)\n",
    "    subset_words = query_words[batch_start:batch_end]\n",
    "    payload = {\"instances\" : subset_words}\n",
    "    #response = bt_endpoint.predict(json.dumps(payload))\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                      Body=json.dumps(payload))\n",
    "    response_str = response['Body'].read().decode()\n",
    "    vecs = json.loads(response_str)\n",
    "    for i in vecs:\n",
    "        arr = np.array(i[\"vector\"], dtype=float)\n",
    "        if np.linalg.norm(arr) == 0:\n",
    "            continue\n",
    "        vectors[i[\"word\"]] = arr\n",
    "    batch_start += batch_size\n",
    "    batch_end += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que obtivemos todos os vetores, podemos calcular o coeficiente de correlação de Spearman entre o julgamento humano e a semelhança de cosseno entre as representações de vetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysim = []\n",
    "gold = []\n",
    "dropped = 0\n",
    "nwords = 0\n",
    "\n",
    "def similarity(v1, v2):\n",
    "    n1 = np.linalg.norm(v1)\n",
    "    n2 = np.linalg.norm(v2)\n",
    "    return np.dot(v1, v2) / n1 / n2\n",
    "\n",
    "fin = open(\"datasets/textmining/rw/rw.txt\", 'rb')\n",
    "for line in fin:\n",
    "    tline = line.decode('utf8').split()\n",
    "    word1 = tline[0].lower()\n",
    "    word2 = tline[1].lower()\n",
    "    nwords += 1\n",
    "\n",
    "    if (word1 in vectors) and (word2 in vectors):\n",
    "        v1 = vectors[word1]\n",
    "        v2 = vectors[word2]\n",
    "        d = similarity(v1, v2)\n",
    "        mysim.append(d)\n",
    "        gold.append(float(tline[2]))\n",
    "    else:\n",
    "        dropped += 1\n",
    "fin.close()\n",
    "\n",
    "corr = stats.spearmanr(mysim, gold)\n",
    "print(\"Correlation: %s, Dropped words: %s%%\" % (corr[0] * 100, math.ceil(dropped / nwords * 100.0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Podemos esperar um coeficiente de correlação de ~ 40, o que é muito bom para um pequeno conjunto de dados de treinamento como o text8. Para obter mais detalhes, consulte [Enriching Word Vectors with Subword Information](https://arxiv.org/pdf/1607.04606.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parar e apagar o Endpoint (Recomendado)\n",
    "Não se esqueça de apagar o endpoint! Pode ser pelo portal ou pelo comando abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "sess.delete_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
